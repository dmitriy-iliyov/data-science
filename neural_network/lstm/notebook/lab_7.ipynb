{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPRJiLhSe9iqD1oBIhT5NmZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmitriy-iliyov/data-science/blob/main/neural_network/lstm/notebook/lab_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "datasets_dir = '/content/drive/MyDrive/data/reviews'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNL79UeErGoZ",
        "outputId": "cd92f3b7-baf8-436f-9bc8-5274e4921dfc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7ScdAKRTmh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60891ce7-554c-4779-9623-d65a04f2dd61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/drive/MyDrive/kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset\n",
            "License(s): other\n",
            "Downloading yelp-dataset.zip to /content/drive/MyDrive/data/reviews/yelp-dataset\n",
            "100% 4.07G/4.07G [00:53<00:00, 82.8MB/s]\n",
            "100% 4.07G/4.07G [00:53<00:00, 81.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "!cp /content/drive/MyDrive/kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "path = \"yelp-dataset/yelp-dataset\"\n",
        "\n",
        "dir_name = path.split('/')[1]\n",
        "current_dir_path = os.path.join(datasets_dir, dir_name)\n",
        "\n",
        "os.makedirs(current_dir_path, exist_ok=True)\n",
        "\n",
        "!kaggle datasets download -d {path} -p {current_dir_path}\n",
        "\n",
        "zip_file_path = os.path.join(current_dir_path, f\"{dir_name}.zip\")\n",
        "!unzip -q {zip_file_path} -d {current_dir_path}\n",
        "\n",
        "os.remove(zip_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def read_data(d):\n",
        "  reviews = []\n",
        "  stars = []\n",
        "  with open(datasets_dir + '/yelp-dataset/yelp_academic_dataset_review.json', encoding='utf-8') as file:\n",
        "    count = 0\n",
        "    for line in file:\n",
        "      jsoned_line = json.loads(line)\n",
        "      reviews.append(jsoned_line['text'])\n",
        "      stars.append(jsoned_line['stars'])\n",
        "      count += 1\n",
        "      if count >= d:\n",
        "        break\n",
        "  return reviews, stars\n"
      ],
      "metadata": {
        "id": "3XC3vAmFsQEz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import *\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "def _start_pre_processing(doc):\n",
        "    doc = re.sub(r'http[s]?://\\S+|www\\.\\S+', '', doc)\n",
        "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I | re.A)\n",
        "    doc = doc.lower()\n",
        "    doc = doc.strip()\n",
        "    wpt = WordPunctTokenizer()\n",
        "    tokens = wpt.tokenize(doc)\n",
        "    custom_stopwords = set(stopwords.words('english')) - {\n",
        "    'not', 'very', 'never', 'no', 'nothing', 'more', 'less', 'good', 'great', 'happy',\n",
        "    'excellent', 'amazing', 'bad', 'horrible', 'sad', 'angry', 'worse', 'could', 'should',\n",
        "    'would', 'might', 'may', 'absolutely', 'completely', 'totally', 'think', 'opinion'\n",
        "    }\n",
        "    filtered_tokens = [token for token in tokens if token not in custom_stopwords]\n",
        "    doc = ' '.join(filtered_tokens)\n",
        "    return doc\n",
        "\n",
        "\n",
        "def _str_pre_processing(_str):\n",
        "    sentences = _str.split('.')\n",
        "    prepared_corpus = [_start_pre_processing(sentence) for sentence in sentences]\n",
        "    prepared_corpus = ' '.join(list(filter(None, prepared_corpus)))\n",
        "    return prepared_corpus\n",
        "\n",
        "\n",
        "def do_pre_processing(doc):\n",
        "    if isinstance(doc, str):\n",
        "        return _str_pre_processing(doc)\n",
        "    else:\n",
        "        print(\"ERROR:   TextPreProcessor can't prepare this type of data.\")\n",
        "        return None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSBRDnlb1Va-",
        "outputId": "319bbefb-544b-4986-f487-f41fba6a7d95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Input\n",
        "from keras.initializers import Constant\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "\n",
        "def prepare_reviews(reviews, max_text_len, pre_processing):\n",
        "    if(pre_processing):\n",
        "        reviews = [do_pre_processing(review) for review in reviews]\n",
        "\n",
        "    tokenizer = Tokenizer()\n",
        "    tokenizer.fit_on_texts(reviews)\n",
        "    reviews = tokenizer.texts_to_sequences(reviews)\n",
        "    print(f'rewiev example: {reviews[0]}')\n",
        "\n",
        "    reviews = pad_sequences(reviews, maxlen=max_text_len)\n",
        "\n",
        "    return reviews, len(tokenizer.word_index)\n",
        "\n",
        "\n",
        "def prepare_stars(stars):\n",
        "    stars = np.array(stars)\n",
        "    stars = stars.reshape(-1, 1)\n",
        "    encoder = OneHotEncoder()\n",
        "    stars = encoder.fit_transform(stars).toarray()\n",
        "    stars = np.array(stars).astype(int)\n",
        "    print(f'star example: {stars[0]}')\n",
        "    return stars\n",
        "\n",
        "\n",
        "def downsampling(reviews, stars):\n",
        "    reviews = np.array(reviews)\n",
        "    stars = np.array(stars).astype(int)\n",
        "\n",
        "    class_counts = np.bincount(stars)[1:]\n",
        "    min_count = np.min(class_counts)\n",
        "    print(f'class counts before downsampling: {class_counts}')\n",
        "\n",
        "    balanced_reviews = []\n",
        "    balanced_stars = []\n",
        "\n",
        "    for star in np.unique(stars):\n",
        "      class_reviews = reviews[stars == star]\n",
        "      class_stars = stars[stars == star]\n",
        "\n",
        "      if len(class_reviews) > min_count:\n",
        "          class_reviews_resampled, class_stars_resampled = resample(class_reviews,\n",
        "                                                                    class_stars,\n",
        "                                                                    replace=False,\n",
        "                                                                    n_samples=min_count,\n",
        "                                                                    random_state=42)\n",
        "          balanced_reviews.extend(class_reviews_resampled)\n",
        "          balanced_stars.extend(class_stars_resampled)\n",
        "      else:\n",
        "          balanced_reviews.extend(class_reviews)\n",
        "          balanced_stars.extend(class_stars)\n",
        "\n",
        "    balanced_reviews = np.array(balanced_reviews)\n",
        "    balanced_stars = np.array(balanced_stars)\n",
        "\n",
        "    class_counts = np.bincount(balanced_stars)[1:]\n",
        "    print(f'class counts after downsampling: {class_counts}')\n",
        "\n",
        "    balanced_reviews, balanced_stars = shuffle(balanced_reviews, balanced_stars, random_state=42)\n",
        "\n",
        "    return balanced_reviews, balanced_stars\n",
        "\n",
        "\n",
        "def prepare_data(d, k, max_text_len, pre_processing = True):\n",
        "\n",
        "    reviews, stars = read_data(d)\n",
        "\n",
        "    reviews, stars = downsampling(reviews, stars)\n",
        "\n",
        "    reviews, word_count = prepare_reviews(reviews, max_text_len, pre_processing)\n",
        "    print(f'reviews count: {len(reviews)}')\n",
        "\n",
        "    stars = prepare_stars(stars)\n",
        "\n",
        "\n",
        "    index = int(k * len(reviews))\n",
        "    train_data = reviews[:index]\n",
        "    train_answers = stars[:index]\n",
        "    test_data = reviews[index:]\n",
        "    test_answers = stars[index:]\n",
        "\n",
        "    return train_data, train_answers, test_data, test_answers, word_count\n"
      ],
      "metadata": {
        "id": "qPfyU3PStG7k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "\n",
        "class DivergenceEarlyStopping(Callback):\n",
        "    def __init__(self, patience=3, restore_best_weights=True):\n",
        "        super().__init__()\n",
        "        self.monitor = 'loss'\n",
        "        self.patience = patience\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.best_weights = None\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.previous_train_loss = None\n",
        "        self.previous_val_loss = None\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_loss = logs.get(f'{self.monitor}')\n",
        "        val_loss = logs.get(f'val_{self.monitor}')\n",
        "\n",
        "        if self.previous_train_loss is None:\n",
        "            self.previous_train_loss = train_loss\n",
        "            self.previous_val_loss = val_loss\n",
        "            return\n",
        "\n",
        "        if val_loss > train_loss:\n",
        "            self.stopped_epoch = epoch\n",
        "            self.model.stop_training = True\n",
        "\n",
        "        if self.wait >= self.patience:\n",
        "            self.stopped_epoch = epoch\n",
        "            self.model.stop_training = True\n",
        "\n",
        "        self.previous_train_loss = train_loss\n",
        "        self.previous_val_loss = val_loss\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.stopped_epoch > 0 and self.restore_best_weights:\n",
        "            self.model.set_weights(self.best_weights)\n",
        "\n"
      ],
      "metadata": {
        "id": "XLRiGMdFVqvo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Input\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "class KerasLSTM:\n",
        "\n",
        "    def __init__(self, word_count, max_length):\n",
        "        self._model = Sequential([\n",
        "            Input(shape=(max_length,)),\n",
        "            Embedding(input_dim=word_count + 1, output_dim=128, input_length=max_length),\n",
        "            LSTM(128, activation='tanh', return_sequences=False),\n",
        "            Dense(5, activation='softmax')\n",
        "        ])\n",
        "        self._model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    def summary(self):\n",
        "        self._model.summary()\n",
        "\n",
        "    def fit(self, train_data, train_answers, validation_split=0.2, epochs=100, batch_size=128):\n",
        "        start_time = time.time()\n",
        "        early_stopping = DivergenceEarlyStopping()\n",
        "        history = self._model.fit(\n",
        "            train_data, train_answers,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            validation_split=validation_split,\n",
        "            callbacks=[early_stopping]\n",
        "        )\n",
        "        execution_time = time.time() - start_time\n",
        "        print(f\"Training completed in {execution_time:.2f} seconds.\")\n",
        "        self.plot_history(history, execution_time)\n",
        "        self.save()\n",
        "        return history, execution_time\n",
        "\n",
        "    def evaluate(self, test_data, test_answers):\n",
        "        test_loss, test_accuracy = self._model.evaluate(test_data, test_answers, verbose=1)\n",
        "        print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n",
        "        return test_loss, test_accuracy\n",
        "\n",
        "    def predict(self, sequence):\n",
        "        return self._model.predict(sequence)\n",
        "\n",
        "    def save(self, path='/content/drive/MyDrive/main/languages/Python/neural_network/labs/lab_7/model/lstm_model.keras'):\n",
        "        self._model.save(path)\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_history(history, execution_time):\n",
        "        epochs = len(history.history['loss'])\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(range(1, epochs + 1), history.history['accuracy'], label='Training Accuracy')\n",
        "        if 'val_accuracy' in history.history:\n",
        "            plt.plot(range(1, epochs + 1), history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.title(f'Accuracy (Execution Time: {execution_time:.2f} seconds)')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(range(1, epochs + 1), history.history['loss'], label='Training Loss')\n",
        "        if 'val_loss' in history.history:\n",
        "            plt.plot(range(1, epochs + 1), history.history['val_loss'], label='Validation Loss')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "SNjW-YQGrvyK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device('/GPU:0'):\n",
        "  reviews_count = 100000\n",
        "  max_length = 100\n",
        "  train_data, train_answers, test_data, test_answers, word_count = prepare_data(reviews_count, 0.8, max_length)\n",
        "\n",
        "  print(f'Vocabulary length: {word_count}')\n",
        "\n",
        "  lstm = KerasLSTM(word_count, max_length)\n",
        "  lstm.summary()\n",
        "\n",
        "  lstm.fit(train_data, train_answers)\n",
        "\n",
        "  count = 20\n",
        "\n",
        "  predicting_data = test_data[:count].copy()\n",
        "  predicting_answers = test_answers[:count].copy().tolist()\n",
        "  test_data = test_data[count:]\n",
        "  test_answers = test_answers[count:]\n",
        "\n",
        "  lstm.evaluate(test_data, test_answers)\n",
        "\n",
        "  for i, data in enumerate(predicting_data):\n",
        "      data = data.reshape(1, -1)\n",
        "      predicted_vec = lstm.predict(data)[0].tolist()\n",
        "      max_val_in_vec = max(predicted_vec)\n",
        "      predicted_val_index = predicted_vec.index(max_val_in_vec)\n",
        "      predicterd_val = predicted_val_index+1\n",
        "      print(f\"real stars: {(predicting_answers[i].index(1)) + 1}; predicted: {predicterd_val}\")"
      ],
      "metadata": {
        "id": "lnnLWD1Xu5p6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "ebf62cc3-e37a-4e85-92b1-6de2d53b0eb5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class counts before downsampling: [10921  7988 11362 25337 44392]\n",
            "class counts after downsampling: [7988 7988 7988 7988 7988]\n",
            "rewiev example: [4, 6, 352, 1807, 1682, 37, 609, 56, 838, 856, 1095, 714, 1155, 7235, 873, 22, 2, 363, 491, 13164, 2003, 181, 417, 250, 231, 991, 37, 3769, 182, 2457, 1150, 505, 155, 1246, 100, 2150, 782, 471, 275, 575, 4, 5431, 8, 403, 16, 7, 145, 10154, 2815, 587, 38, 18, 5256, 822, 1682, 37, 242, 3, 5432, 105, 884, 798, 285, 92, 499, 119, 16, 187, 1690, 10155, 1081, 471, 2]\n",
            "reviews count: 39940\n",
            "star example: [0 0 0 1 0]\n",
            "Vocabulary length: 53723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m6,876,672\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,876,672</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,008,901\u001b[0m (26.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,008,901</span> (26.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,008,901\u001b[0m (26.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,008,901</span> (26.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 307ms/step - accuracy: 0.4355 - loss: 1.2650 - val_accuracy: 0.5578 - val_loss: 1.0072\n",
            "Epoch 2/100\n",
            "\u001b[1m799/799\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 287ms/step - accuracy: 0.6637 - loss: 0.8061 - val_accuracy: 0.5636 - val_loss: 1.0279\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-7102d2934e73>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_answers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-833adae22239>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, train_answers, validation_split, epochs, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDivergenceEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         history = self._model.fit(\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_answers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-417cd44e1494>\u001b[0m in \u001b[0;36mon_train_end\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped_epoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ]
    }
  ]
}